Idiomatic Optimization:  simpler, faster R code 
========================================================
author: Robert Horton, PhD, MS
date: December 8, 2014


```{r setup, echo=FALSE}
opts_knit$set(width = 90)
par(cex=1.5)
require(ggplot2)
```

Intended Audience
========================================================
This presentation assumes that you: 
* have some experience with R programming
* know how to decompose problems and write functions
* are familiar with the fundamental R data structures
* can write code that gives correct answers, even if it is slow
* want to make your code simpler and faster

Idiomatic Optimization
========================================================

```{r venn_diagram, echo=FALSE}
drawCircle <- function(x, y, r, ...){
    ANGLES <- (1:360) * (2 * pi / 360)
    polygon(x + r*sin(ANGLES), y + r * cos (ANGLES), ...)
}

op <- par( mar=rep(0,4) )
r <- 25
sep <- 30
plot(1:(sep + 2*r), 1:(sep + 2*r), type="n", bty="n")
drawCircle(r + sep/2, r, r, col="#FF000040", angle=c(-45,45))
drawCircle(r, r + sep * sqrt(3)/2, r, col="#00FF0040", angle=c(-45,45))
drawCircle(r + sep, r + sep * sqrt(3)/2, r, col="#0000FF40", angle=c(-45,45))

text(x=c(r/2 + sep - 3, r/2 + 5, r/2 + 2*sep - 10), 
     y=c(r/2, r/2 + sep * sqrt(3), r/2 + sep * sqrt(3)), 
    labels=c("fast", "clear", "concise"), cex=3, col=c("#400000", "#004000", "#000040"))
par(op)
```
***
We will look at ways to make your code shorter, easier to understand, and faster, all at the same time.

This is not premature optimization; we want to make the code concise and clear anyway.


Quiz
========================================================
```{r microbenchmark_setup, echo=FALSE}
require(microbenchmark)
require(ggplot2)
```
Given a function like this:
```{r euler_limit}
f <- function(n) (1 + 1/n)^n
```
What is the fastest way to run the function on a series of inputs?
* y <- numeric(); for (i in seq_along(x)) y[i] <- f(x[i])
* y <- numeric(length(x)); for (i in seq_along(x)) y[i] <- f(x[i])
* y <- sapply(x, f)
* y <- vapply(x, f, numeric(1))


Trick Question!  y <- f(x)
========================================================
```{r setup_microbenchmark}
x <- 1:1000
```
```{r run_microbenchmark, echo=FALSE, cache=TRUE, fig.width=14, fig.height=6}
res <- microbenchmark(
    y <- vapply(x, f, numeric(1)),
    y <- sapply(x, f),    
	{y <- numeric(length(x));
	for (i in seq_along(x)) y[i] <- f(x[i])},
    {y <- numeric();
	for (i in seq_along(x)) y[i] <- f(x[i])},
    y <- f(x),     
	times=50
)
op <- par(cex=2)
autoplot(res) + theme_grey(base_size = 28)
par(op)
```


Performance
========================================================
```{r time_these_functions, echo=FALSE}
# pre-allocate a list: y <- vector("list", N)
f <- function(n) (1 + 1/n)^n
time_these_functions <- c(
    growing_memory = function(N){
        y <- numeric()
    	for (i in 1:N) y[i] <- f(i)
		y
	},

	pre_allocated = function(N){
		y <- numeric(N)
		for (i in 1:N) y[i] <- f(i)
		y
	},

    sapplied = function(N){
        sapply(1:N, f)
	},

    vapplied = function(N){
		vapply(1:N, f, 1)
	},

	vectorized = f
)
```
```{r performance_code, echo=FALSE}
color_vector <- rainbow(length(time_these_functions), v=0.5)
    # v=0.5 makes the colors darker
names(color_vector) <- names(time_these_functions)

plot_timings <- function( function_vector, max_N=1e4, line_colors=color_vector ){
    
    vector_length <- seq(0, max_N, length=101)
    
    get_time <- function(param, fun, attr="elapsed")
    	summary(system.time( fun(param) ))[attr]
    
    timing_results <- data.frame( 
    	N = vector_length, 
    	lapply(function_vector, function(f){
    		sapply(vector_length, get_time, f)
    	})
    )
  
    with(timing_results, {
    	plot(N, timing_results[[2]], type='n', ylab="elapsed time (sec)", cex=2)
    	for (funcName in names(function_vector))
    		lines(N, timing_results[[funcName]], col=line_colors[funcName])
    	legend("topleft", lty=1, lwd=2, bty='n', 
               col=line_colors[names(function_vector)],
               text.col=line_colors[names(function_vector)], 
               legend=names(function_vector) )
    })
}
```
```{r performance_fig1, echo=FALSE, cache=TRUE, fig.width=12, fig.height=8}
op <- par(cex=2)
plot_timings(time_these_functions)
par(op)
```

Case Study
========================================================

[![Machine Learning for Hackers](http://akamaicovers.oreilly.com/images/0636920018483/lrg.jpg)](http://shop.oreilly.com/product/0636920018483.do)
***
* Book organized as a series of case studies presenting increasingly complex machine learning approaches
* Programming perspective, rather than straight math
* Well-known authors, respected publisher, fairly popular book
* Examples are all in R
* Code is not idiomatic

Code Breaking as an Optimization Problem
========================================================
* Toy problem: use Metropolis algorithm to solve a simple substitution cipher
    - A (secret) permutation of the alphabet has been used to encipher a message
    - Try to find the best permutation to reverse the cipher
* Uses a large dictionary of English words and their observed probability of occurrence in training text
    - look for recognizable words in output
    - score message by product of word probabilities
* Requires many iterations of testing and modification

Improvement of Scores Across Iterations
========================================================

```{r optimized_code, echo=FALSE}
alphabet <- paste(letters, collapse='')
encipher <- function(string, cipher) chartr(alphabet, cipher, string)
decipher <- function(cryptstring, cipher) chartr(cipher, alphabet, cryptstring)

generate.random.cipher <- function() paste(sample(letters), collapse='')

propose.modified.cipher <- function(cipher){
    in_position <- sample(seq_along(letters),1)
    in_char <- substr(cipher, in_position, in_position)
	out_char <- sample(letters, 1)
	old_order <- paste0(in_char, out_char)
	new_order <- paste0(out_char, in_char)
	chartr(old_order, new_order, cipher)
}

lexmap_factory <- function(){
	# load(file.path('data', 'lexical_database.Rdata'))
	lex_data_url <- paste0("https://raw.githubusercontent.com/johnmyleswhite/",
							"ML_for_Hackers/master/07-Optimization/", 
							"data/lexical_database.Rdata")
	load( pipe(paste("curl", lex_data_url)) )

	LEXMAP <- new.env(size=length(lexical.database))
	for (i in seq_along(lexical.database))
		LEXMAP[[ names(lexical.database)[i] ]] <- log(lexical.database[[i]])

	MIN_SCORE <- log(.Machine$double.eps)

	function(text_vec){
		log_prob_list <- mget(text_vec, env=LEXMAP, ifnotfound=MIN_SCORE)
		sum(unlist(log_prob_list))
	}
}

log.probability.of.text <- lexmap_factory()

metropolis.step <- function(cipher.text, cipher){
	proposed.cipher <- propose.modified.cipher(cipher)

	lp1 <- log.probability.of.text(encipher(cipher.text, cipher))
	lp2 <- log.probability.of.text(encipher(cipher.text, proposed.cipher))

	if (lp2 > lp1) {
		proposed.cipher
	} else {
		a <- exp(lp2 - lp1)
		x <- runif(1)

		if (x < a) {
			proposed.cipher
		} else {
			cipher
		}
	}
}

break_cipher <- function(encrypted.text, decrypted.text="optional", 
					number.of.iterations=50000, seed=1, verbose=FALSE){
	set.seed(seed)
	cipher <- generate.random.cipher()

	results <- matrix( character(5 * number.of.iterations), nrow=number.of.iterations)
	for (iteration in 1:number.of.iterations){
		# If we were trying to find the original cipher, we would use "decipher";
		# we are looking for the inverse cipher.
		guessed.text <- encipher(encrypted.text, cipher)

		log.probability <- log.probability.of.text(guessed.text)

		correct.text <- as.integer( all(guessed.text == decrypted.text) )

		results[iteration,] <- c(	Iteration = iteration,
					LogProbability = log.probability,
					CurrentDecryptedText = paste(guessed.text, collapse = ' '),
					cipher = cipher,
					CorrectText = correct.text)
		
		cipher <- metropolis.step(encrypted.text, cipher)

		if ( (iteration %% 1000 == 0) & verbose )
			print(paste(c(results[iteration,]), collapse=' '))
	}
	results <- as.data.frame(results, stringsAsFactors=F)
	names(results) <- c('Iteration','LogProbability','CurrentDecryptedText',
						'cipher','CorrectText')
	results$Iteration <- as.integer(results$Iteration)
	results$LogProbability <- as.numeric(results$LogProbability)
	
	results
}

```
```{r run_iterations, echo=FALSE, cache=TRUE}
decrypted.text <- c('here', 'is', 'some', 'sample', 'text')
caesar <- paste(letters[seq_along(letters) %% 26 + 1], collapse='')
encrypted.text <- encipher(decrypted.text, caesar)
num_iterations <- 5e4
res <- break_cipher(encrypted.text, decrypted.text, num_iterations)
```
```{r plot_res, echo=FALSE}
g <- ggplot(res, aes(x=Iteration, y=LogProbability)) + geom_line()

sample_points <- c(1, 10000, 30000, 50000)
annot_x <- c(700, 3000, 22000, 32000)
annot_y <- c(-175, -80, -50, -30)
annot_txt <- res$CurrentDecryptedText[sample_points]

g + annotate("text", x=annot_x, y=annot_y, label=annot_txt, hjust=0, col="blue")
```
***
* actual message: 
<div>"`r paste(decrypted.text, collapse=" ")`"</div>
* caesar cipher: "`r caesar`"
* total iterations: `r num_iterations`
* final decryption: 
<div>"`r res$CurrentDecryptedText[num_iterations]`"</div>

Time Comparisons
========================================================
```{r timing_table, echo=FALSE}
# profiling run 1: 50 iterations in 1.78 sec
# first full run of version 1 took 2824.419 sec
timings <- data.frame(
    version = c("1","2","3","4","final"),
    iterations = c( 50000, 5000, 5000, 5000, 50000),
    times = c( 2579.266, 24.26, 11.44, 9.42, 12.912 )
)
timings$total_time <- with(timings, 50000 * times / iterations)
```
```{r timing_chart, echo=FALSE}
require(ggplot2)
ggplot(timings, aes(x=version, y=total_time)) + 
        geom_bar(stat="identity")
```
***
Total time for 50000 iterations was reduced from 
`r sprintf("%0.1f", timings[timings$version=="1","total_time"]/60)` minutes to 
`r sprintf("%0.1f", timings[timings$version=="final","total_time"])` seconds
(a `r round(timings[timings$version=="1","total_time"]/timings[timings$version=="final","total_time"])`-fold improvement).

Length of code was reduced by half.

Profiling run #1
========================================================
(50 iterations in 1.78 sec)
```
                    self.time self.pct
"one.gram.probability"   1.56    91.76
"paste"                  0.04     2.35
"rbind"                  0.02     1.18
"as.data.frame.character"0.02     1.18
"factor"                 0.02     1.18
"make.names"             0.02     1.18
"unlist"                 0.02     1.18

```

one.gram.probability
========================================================
```
one.gram.probability <- 
    function(one.gram, lexical.database=list())
{
  lexical.probability <- 
        lexical.database[[one.gram]]
...
```

`lexical.database` is a list where the keys are English words and the values are the relative frequencies of the word in a training text.

Solution #1: environment vs. list
========================================================

In a list, looking up values by key requires sequential search in a list. An environment uses hashing to find values by key in constant time.

```
LEXMAP <- new.env(size=length(lexical.database))
for (i in seq_along(lexical.database))
    LEXMAP[[ names(lexical.database)[i] ]] <- lexical.database[[i]]
```

When copying the dictionary, using an integer index into the original list with double bracket operator is dramatically faster than looking up each word by name.

Profiling run #2
========================================================
(5000 iterations in 24.26 sec)
```
                    self.time self.pct
"rbind"                  3.94    16.32
"paste"                  2.94    12.18
"match"                  2.48    10.27
"[<-.factor"             1.66     6.88
"as.vector"              1.28     5.30
"apply.cipher.to.string" 0.68     2.82
"deparse"                0.54     2.24
"levels"                 0.54     2.24

```

Problem #2: growing results a row at a time
========================================================
```
results <- data.frame()

for (iteration in 1:number.of.iterations){
  ...
  results <- rbind(results,data.frame...
```
  
Solution #2: combine all the rows at once
========================================================

```
results <- do.call("rbind", 
    lapply(1:number.of.iterations, 
        function(i){...
```

Each iteration produces a one-row data frame, and we need to bind them all together. The `rbind` function takes a series of arguments and combines them by rows. We can do the iterations using `lapply` so that the single-row data frames are in a list, then use `do.call` to run `rbind` with all the rows at once.

Profiling run #3
========================================================
(5000 iterations, 11.44 sec)
```
                     self.time self.pct
"paste"                   3.50    30.59
"substr"                  0.80     6.99
"rbind"                   0.66     5.77
"apply.cipher.to.string"  0.60     5.24
"data.frame"              0.48     4.20
"deparse"                 0.44     3.85
"make.names"              0.44     3.85
"as.data.frame"           0.36     3.15
```

Problem #3: string operations
========================================================
```
apply.cipher.to.string <- function(string, cipher)
{
  output <- ''

  for (i in 1:nchar(string))
  {
    output <- paste(output, 
        cipher[[substr(string, i, i)]], 
        sep = '')
  }
  
  return(output)
}
```

Solution #3: vapply the cipher
========================================================
```{r apply_cipher_to_string, eval=FALSE}
apply.cipher.to.text <- 
        function(text, cipher){
    encipher_vec <- function(ch_vec, cipher)
        paste(cipher[ch_vec], collapse='')
	vapply(strsplit(text,''), 
        encipher_vec, character(1), cipher)
}

```

Profiling run #4
========================================================
(5000 iterations in 9.42 sec)
```
                     self.time self.pct
"rbind"                   0.96    10.19
"paste"                   0.86     9.13
"vapply"                  0.62     6.58
"FUN"                     0.60     6.37
"strsplit"                0.52     5.52
"deparse"                 0.44     4.67
"log.probability.of.text" 0.34     3.61

```

Final Version: multiple changes
========================================================
Representing ciphers as strings instead of named vectors allows fast and simple character translation using `chartr`.

```
generate.random.cipher <- function()
    paste(sample(letters), collapse='')

alphabet <- paste(letters, collapse='')
encipher <- function(string, cipher)
        chartr(alphabet, cipher, string)
```

Collecting the results for each iteration in the corresponding row of a pre-allocated character matrix, then converting to a data frame at the end of the run, is much faster than `rbind` on single-row data frames.

Final Profiling Run
========================================================
(50000 iterations in 12.9 sec)
```
                 self.time self.pct
"chartr"              3.38    29.14
"sample.int"          1.38    11.90
"mget"                1.26    10.86
"unlist"              1.06     9.14
".External"           0.80     6.90
"c"                   0.70     6.03
"paste0"              0.66     5.69
"break_cipher"        0.38     3.28
"paste"               0.34     2.93
"sample"              0.30     2.59
```

Idioms in R
========================================================
* Process data by batch, not by item
    - <span style="color:#800">Orchestrate computation</span>: declarative, not imperative
        + Call a solver: `solve(A,b)`, `optim()`, `ode(...)`
        + Use vector (or matrix) operations: `sqrt(vec)`, `%*%`
    - Avoid growing data structures in memory
* R has a rich vocabulary. Use it.
    - Use available functions / packages
    - Use appropriate data structures

_Idiomatic R can be concise, readable, and fast._

Session Info
========================================================
```{r sessionInfo, echo=FALSE, width=40}
sessionInfo()
```
